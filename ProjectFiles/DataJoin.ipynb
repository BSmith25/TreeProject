{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1, DataJoin: To clean and merge 311 service request data with the NYC Street Tree Census\n",
    "** Note that throughout this and other jupyter notebooks, the following terminology is used:\n",
    "- falls: refer to fallen branches (from the 311 service request dataset) since 2015\n",
    "- service requests: refer to 311 service requests for damaged trees or overhanging branches (but NOT fallen branches) since 2015\n",
    "- tree census: refers to the 2015 NYC Street Tree Census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function to match a 311 service request tree with a 2015 Street Tree Census tree_id\n",
    "        input is the address, latitude, and longitude of the 311 service request and the Street Tree Census dataframe\n",
    "        output is the tree_id '''\n",
    "\n",
    "# the function\n",
    "def assign_tree_id(address,lat,lon,df):\n",
    "    # Find all street trees assigned to the same address as the 311 service request\n",
    "    tempdf = df[df.address==address]\n",
    "    # If multiple street trees are assigned to the address, find the one closest to the service request by latitude-longitude distance and output its tree_id\n",
    "    if tempdf.count()['tree_id']>=2:\n",
    "        dis=np.sqrt(np.square(tempdf.latitude-lat)+np.square(tempdf.longitude-lon))\n",
    "        tree_index = np.argmin(np.array(dis))\n",
    "        return tempdf.tree_id.iloc[tree_index]\n",
    "    # If no street trees have the address output nan\n",
    "    elif tempdf.count()['tree_id']==0:\n",
    "        return np.nan\n",
    "    # If only one street tree has the address, output that tree_id\n",
    "    else:\n",
    "        return tempdf.tree_id.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, import and organize the 2015 NYC Street Tree Census data.\n",
    "The tree census data is stored in a GIS shapefile, so it needs to be imported as a geopandas geodataframe and converted to a pandas dataframe.\n",
    "\n",
    "Many of the columns can be dropped, like political boundaries (e.g. state assembly district), information about the data entry, and tree specifics (e.g. species latin name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tree census data as a geopandas geodataframe\n",
    "tree_census_geodf = geopandas.read_file('Data/Trees/2015 Street Tree Census - Tree Data/geo_export_f9cac9c3-66c4-45b6-899b-823a270d8754.shp')\n",
    "\n",
    "# Convert tree census data into a pandas dataframe, remove un-needed columns, and remove geometry columns\n",
    "tree_census_df = pd.DataFrame(tree_census_geodf.drop(columns='geometry'), copy=True)\n",
    "tree_census_df.drop(['boro_ct', 'borocode', 'boroname', 'brnch_ligh',\n",
    "       'brnch_othe', 'brnch_shoe', 'cb_num', 'cncldist','nta',\n",
    "       'nta_name','spc_latin', 'st_assem', 'st_senate', 'state','stump_diam','user_type', 'x_sp', 'y_sp', 'zip_city'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, import 311 Tree fall service requests and assign each a street tree census tree_id\n",
    "Several unneeded location columns can be dropped from the 311 requests.\n",
    "\n",
    "Only falls after the tree census date (2015) will be used.  Only branch falls, not entire tree falls, will be used.  All requests for trees in parks (not street trees) will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 311 tree fall service request data and drop unneeded columns\n",
    "fall_df = pd.read_csv('Data/311/Tree_Fall_311.csv',quoting=3)\n",
    "fall_df.drop([\n",
    "       'Street Name', 'Cross Street 1', 'Cross Street 2',\n",
    "       'Intersection Street 1', 'Intersection Street 2', 'Status', 'Borough',\n",
    "       'X Coordinate (State Plane)', 'Y Coordinate (State Plane)'],axis=1, inplace=True)\n",
    "\n",
    "# Remove all falls before 2015 (before the street tree census)\n",
    "fall_df['Created Date'] = pd.to_datetime(fall_df['Created Date'])\n",
    "fall_df = fall_df.where(fall_df['Created Date'] > '2015-01-01')\n",
    "\n",
    "# Remove all falls that occured in parks, and not in street trees\n",
    "fall_df = fall_df.where(fall_df['Location Type'] != 'Park')\n",
    "\n",
    "# Only keep branch falls (eliminate whole tree falls)\n",
    "fall_df=fall_df[fall_df.Descriptor=='Branch or Limb Has Fallen Down']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match each 311 branch fall service request with a street tree census tree_id using the assign_tree_id function defined above.  This matches trees based on address and lat-lon distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to match service request tree falls to street tree census tree_ids, remove service requests without addresses or coordinates\n",
    "fall_df = fall_df[fall_df['Incident Address'].isna()==False]\n",
    "fall_df = fall_df[fall_df.Latitude.isna()==False]\n",
    "fall_df = fall_df[fall_df.Longitude.isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find closest tree from the street tree census and then assign its tree_index to the 311 data frame\n",
    "fall_tree_ids_list = [assign_tree_id(address,lat,lon,tree_census_df.copy()) for address,lat,lon in zip(fall_df['Incident Address'],fall_df['Latitude'],fall_df['Longitude'])]\n",
    "fall_df['tree_id']=fall_tree_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fallen tree ids so I don't need to run that function again\n",
    "fall_df.to_csv('Data/Intermediate/tree_falls_with_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export id columns too, just in case\n",
    "tid_fall_df = pd.DataFrame(fall_df, columns=['tree_id'])\n",
    "tid_fall_df.to_csv('Data/Intermediate/fall_tree_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, import 311 tree damage and overhanging tree service requests and assign each a street tree census tree_id\n",
    "Follow the same process as above with tree falls.  Again only use data from before 2015.  Again remove all requests for trees in parks (not street trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brian\\.conda\\envs\\insight\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Import and organize 311 tree damage and overhanging branch service requests and drop unneeded columns\n",
    "service_request_df = pd.read_csv('Data/311/Tree_Service_Requests_311.csv',quoting=3)\n",
    "service_request_df.drop([\n",
    "       'Street Name', 'Cross Street 1', 'Cross Street 2',\n",
    "       'Intersection Street 1', 'Intersection Street 2', 'Status', 'Borough',\n",
    "       'X Coordinate (State Plane)', 'Y Coordinate (State Plane)'],axis=1,inplace=True)\n",
    "\n",
    "# Remove all service requests before 2015 (before the street tree census)\n",
    "service_request_df['Created Date'] = pd.to_datetime(service_request_df['Created Date'])\n",
    "service_request_df = service_request_df.where(service_request_df['Created Date'] > '2015-01-01')\n",
    "\n",
    "# Remove all falls that occured in parks, and not in street trees\n",
    "service_request_df = service_request_df.where(service_request_df['Location Type'] != 'Park')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match each 311 branch fall service request with a street tree census tree_id using the assign_tree_id function defined above.  This matches trees based on address and lat-lon distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to match service requests to street tree census tree_ids, remove service requests without addresses or coordinates\n",
    "service_request_df = service_request_df[service_request_df['Incident Address'].isna()==False]\n",
    "service_request_df = service_request_df[service_request_df.Latitude.isna()==False]\n",
    "service_request_df = service_request_df[service_request_df.Longitude.isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find closest tree from the street tree census and then assign its tree_index to the 311 data frame\n",
    "tree_ids_service_requests = [assign_tree_id(address,lat,lon,tree_census_df.copy()) for address,lat,lon in zip(service_request_df['Incident Address'],service_request_df.Latitude,service_request_df.Longitude)]\n",
    "service_request_df.tree_id=tree_ids_service_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file with tree ids for damages\n",
    "service_request_df.to_csv('Data/Intermediate/tree_service_requests_with_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export id columns too, just in case\n",
    "tid_service_request_df = pd.DataFrame(service_request_df, columns=[\"tree_id\"])\n",
    "tid_service_request_df.to_csv('Data/Intermediate/service_request_tree_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now merge the street tree census data to branch fall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tree fall df to the street tree census df\n",
    "\n",
    "# First, drop rows without a tree_id from the branch fall df\n",
    "fall_df = fall_df[fall_df.tree_id.isna()==False]\n",
    "\n",
    "# now merge the branch fall df to the street tree census df\n",
    "census_with_falls_df = tree_census_df.merge(fall_df,how=\"left\",left_on=\"tree_id\",right_on=\"tree_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, save this as a csv so we don't need to do it again\n",
    "census_with_falls_df.to_csv('Data/Intermediate/tree_data_with_falls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the service request data with the street tree census data\n",
    "Note the service requests have many potential descriptors (e.g. 'Branch Cracked and Will Fall', 'Tree Leaning/Uprooted') and these will be one hot encoded in the data.  Note that there may be multiple service requests for a tree, but this will only count the presence or absence of the service request type, not the total number.  Also note that only service requests which appeared to influence tree branch falls in EDA are kept in an effort to reduce the number of features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete un-needed clomuns\n",
    "census_with_falls_df.drop(['Unique Key', 'Created Date', 'Closed Date', 'Agency', 'Complaint Type','Location Type', 'Incident Address',\n",
    "       'Latitude', 'Longitude','block_id', 'created_at','latitude', 'longitude', 'problems','status'],axis=1,inplace=True )\n",
    "service_request_df.drop(['Unique Key', 'Created Date', 'Closed Date', 'Agency', 'Complaint Type','Location Type', 'Incident Address',\n",
    "       'Latitude', 'Longitude'],axis=1,inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the desired service requests\n",
    "\n",
    "# First pick the desired service requests\n",
    "service_request_list = ['Branch Cracked and Will Fall', 'Tree Leaning/Uprooted','Hitting Building','Hitting Power/Phone Lines','Dead Branches in Tree','Blocking Street','Tree Alive - in Poor Condition']\n",
    "\n",
    "# Loop through the service request list and one hot encode them by looping through the tree_ids in the service request dataframe\n",
    "# Make a new dataframe, df_temp, from the tree_ids and one hot encoded service requests\n",
    "service_request_tid_list = service_request_df.tree_id.unique()\n",
    "df_temp = pd.DataFrame()\n",
    "df_temp['tree_id']=service_request_tid_list\n",
    "df_temp.dropna(inplace=True)\n",
    "df_temp.set_index('tree_id',inplace=True)\n",
    "for service_request in service_request_list:\n",
    "    df_temp[service_request]=0\n",
    "    for tid in service_request_tid_list:\n",
    "        df_temp.loc[tid,service_request] = service_request_df[service_request_df.tree_id==tid].Descriptor.isin([service_request]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the one hot encoded service requests temporary dataframe so we don't have to run that loop again\n",
    "df_temp.to_csv('Data/Intermediate/tree_id_service_requests.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the one hot encoded service requests temporary dataframe with the tree census dataframe\n",
    "census_with_falls_service_requests_df = census_with_falls_df.merge(df_temp,how=\"left\",left_on=\"tree_id\",right_on=\"tree_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, import and organize the spatial datasets (impervious percentage and building height)\n",
    "Import the the % impervious cover near the tree (10 m squares) and the building height nearest to the tree, this data was generated in QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the impervious % near the tree and closest building height to the tree\n",
    "census_with_imp_bldghght_df = pd.read_csv('Data/spatialdatasets/data_with_imp_bldghght.csv',index_col='tree_id')\n",
    "\n",
    "# Drop un-needed columns from the impervious/building height data\n",
    "census_with_imp_bldghght_df.drop(['address', 'block_id', 'created_at', 'curb_loc', 'guards', 'health',\n",
    "       'latitude', 'longitude', 'problems', 'root_grate', 'root_other',\n",
    "       'root_stone', 'sidewalk', 'spc_common', 'status', 'steward', 'tree_dbh',\n",
    "       'trnk_light', 'trnk_other', 'trnk_wire', 'zipcode'],axis=1,inplace=True)\n",
    "\n",
    "# Some addresses have multiple building heights, so remove duplicate building heights (note that it isn't too important which one is removed since they are typically very similar)\n",
    "census_with_imp_bldghght_df = census_with_imp_bldghght_df(subset='tree_id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, merge the spatial datasets to the tree census data to create the model input dataframe\n",
    "Merge the tree census with branch falls and service request dataframe with the impervious percentage and building height dataframe to a model data dataframe containing all data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tree, fall, and service request data with building height and impervious percentage\n",
    "model_data_df = census_with_falls_service_requests_df.merge(census_with_imp_bldghght_df,how='left',left_index=True,right_on='tree_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the confusing columns of this model dataframe and drop un-needed columns\n",
    "model_data_df.rename(columns={'rvalue_1':'impervious_pct'},inplace=True)\n",
    "model_data_df.rename(columns={'Descriptor':'Fall'},inplace=True)\n",
    "model_data_df.drop('Incident Zip',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model dataframe\n",
    "model_data_df.to_csv('Data/Intermediate/model_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
