{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Organize Tree Survey\n",
    "\n",
    "# Import tree survey data\n",
    "data = geopandas.read_file('Data/Trees/2015 Street Tree Census - Tree Data/geo_export_f9cac9c3-66c4-45b6-899b-823a270d8754.shp')\n",
    "\n",
    "# Turn tree survey data into a normal dataframe and remove a bunch of columns\n",
    "data_nogeom = pd.DataFrame(data.drop(columns='geometry'), copy=True)\n",
    "data_nogeom=data_nogeom.drop(['boro_ct', 'borocode', 'boroname', 'brnch_ligh',\n",
    "       'brnch_othe', 'brnch_shoe', 'cb_num', 'cncldist','nta',\n",
    "       'nta_name','spc_latin', 'st_assem', 'st_senate', 'state','stump_diam','user_type', 'x_sp', 'y_sp', 'zip_city'],axis=1)\n",
    "\n",
    "data_no_geom=data_nogeom.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and organize 311 tree fall data and merge with tree survey data\n",
    "\n",
    "# Import fall data and drop irrelevant columns\n",
    "data_falls = pd.read_csv('Data/311/Tree_Fall_311.csv',quoting=3)\n",
    "data_falls = data_falls.drop([\n",
    "       'Street Name', 'Cross Street 1', 'Cross Street 2',\n",
    "       'Intersection Street 1', 'Intersection Street 2', 'Status', 'Borough',\n",
    "       'X Coordinate (State Plane)', 'Y Coordinate (State Plane)'],axis=1)\n",
    "\n",
    "# Remove the falls before 2015 (before survey)\n",
    "data_falls['Created Date']= pd.to_datetime(data_falls['Created Date'])\n",
    "data_falls = data_falls.where(data_falls['Created Date']>'2015-01-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trees from 311 without addresses and only use trees where branch fell (not entire tree)\n",
    "data_falls = data_falls[data_falls['Incident Address'].isna()==False]\n",
    "data_falls = data_falls[data_falls['Latitude'].isna()==False]\n",
    "data_falls = data_falls[data_falls['Longitude'].isna()==False]\n",
    "data_falls=data_falls[data_falls['Descriptor']=='Branch or Limb Has Fallen Down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find closest tree from the street tree survey and then assign its tree_index to the 311 data frame\n",
    "# Make a copy of the tree census data\n",
    "df=data_no_geom.copy()\n",
    "\n",
    "# Write a function to find tree ids from address and lat lon\n",
    "def assign_tree_id(address,lat,lon,df=df):\n",
    "    tempdf = df[df['address']==address]\n",
    "    if tempdf.count()['tree_id']>=2:\n",
    "        dis=np.sqrt(np.square(tempdf['latitude']-lat)+np.square(tempdf['longitude']-lon))\n",
    "        tree_index = np.argmin(np.array(dis))\n",
    "        return tempdf.tree_id.iloc[tree_index]\n",
    "    elif tempdf.count()['tree_id']==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return tempdf['tree_id'].to_numpy()[0]\n",
    "    \n",
    "# find 311 branch fall tree ids\n",
    "tree_ids = [assign_tree_id(address,lat,lon) for address,lat,lon in zip(data_falls['Incident Address'],data_falls['Latitude'],data_falls['Longitude'])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fallen tree ids\n",
    "data_falls['tree_id']=tree_ids\n",
    "data_falls.to_csv('Data/Intermediate/tree_falls_with_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and organize 311 tree damage data and overhang calls and merge with tree survey data\n",
    "\n",
    "# Import damage data and drop irrelevant columns\n",
    "data_damage = pd.read_csv('Input_Data/Tree_Damage_311_Final.csv',quoting=3)\n",
    "data_damage = data_damage.drop([\n",
    "       'Street Name', 'Cross Street 1', 'Cross Street 2',\n",
    "       'Intersection Street 1', 'Intersection Street 2', 'Status', 'Borough',\n",
    "       'X Coordinate (State Plane)', 'Y Coordinate (State Plane)'],axis=1)\n",
    "\n",
    "# Remove trees from 311 damages without addresses \n",
    "data_damage = data_damage[data_damage['Incident Address'].isna()==False]\n",
    "data_damage = data_damage[data_damage['Latitude'].isna()==False]\n",
    "data_damage = data_damage[data_damage['Longitude'].isna()==False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign tree ids to 311 warning data\n",
    "\n",
    "# Find closest tree from the street tree survey and then assign its tree_index to the 311 data frame\n",
    "tree_ids_damage = [assign_tree_id(address,lat,lon) for address,lat,lon in zip(data_damage['Incident Address'],data_damage['Latitude'],data_damage['Longitude'])]\n",
    "data_damage['tree_id']=tree_ids_damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file with tree ids for damages\n",
    "data_damage.to_csv('Data/Intermediate/tree_damage_with_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export id columns too\n",
    "tid_damage_df = pd.DataFrame(tree_ids_damage, columns=[\"tree_id\"])\n",
    "tid_damage_df.to_csv('Data/Intermediate/damage_tree_id.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tree falls and tree survey\n",
    "# drop rows without a tree_id\n",
    "data_falls = data_falls[data_falls['tree_id'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now merge\n",
    "data_with_falls = data_nogeom.merge(data_falls,how=\"left\",left_on=\"tree_id\",right_on=\"tree_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this so we don't need to do it again\n",
    "data_with_falls.to_csv('Data/Intermediate/tree_data_with_falls.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
